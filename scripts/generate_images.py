"""
åœ–ç‰‡ç”Ÿæˆæ¨¡çµ„ - ä½¿ç”¨æœ¬åœ° Stable Diffusion
ç‚ºæ¯å€‹æ®µè½ç”Ÿæˆå°æ‡‰çš„èƒŒæ™¯åœ–ç‰‡
"""

import os
import sys
from typing import List, Dict
from PIL import Image
import torch
from diffusers import StableDiffusionPipeline, StableDiffusionXLPipeline
import json


class ImageGenerator:
    def __init__(
        self,
        model_type: str = "sdxl",  # "sdxl" or "sd15"
        device: str = None,
        output_dir: str = "images"
    ):
        """
        åˆå§‹åŒ–åœ–ç‰‡ç”Ÿæˆå™¨
        
        Args:
            model_type: æ¨¡å‹é¡å‹ "sdxl" æˆ– "sd15"
            device: è¨­å‚™ ("cuda", "cpu", "mps")
            output_dir: è¼¸å‡ºç›®éŒ„
        """
        self.model_type = model_type
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.output_dir = output_dir
        self.pipeline = None
        
        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        print(f"ğŸ–¼ï¸  åœ–ç‰‡ç”Ÿæˆå™¨åˆå§‹åŒ–ï¼Œè¨­å‚™: {self.device}")
    
    def load_model(self):
        """è¼‰å…¥ Stable Diffusion æ¨¡å‹"""
        try:
            print(f"ğŸ“¦ æ­£åœ¨è¼‰å…¥ {self.model_type} æ¨¡å‹...")
            
            if self.model_type == "sdxl":
                # SDXL æ¨¡å‹ï¼ˆéœ€è¦æ›´å¤š VRAMï¼‰
                model_id = "stabilityai/stable-diffusion-xl-base-1.0"
                self.pipeline = StableDiffusionXLPipeline.from_pretrained(
                    model_id,
                    torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                    use_safetensors=True
                )
            else:
                # SD 1.5 æ¨¡å‹ï¼ˆè¼ƒè¼•é‡ï¼‰
                model_id = "runwayml/stable-diffusion-v1-5"
                self.pipeline = StableDiffusionPipeline.from_pretrained(
                    model_id,
                    torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                    use_safetensors=True
                )
            
            self.pipeline = self.pipeline.to(self.device)
            
            # å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨
            if self.device == "cuda":
                self.pipeline.enable_attention_slicing()
                self.pipeline.enable_vae_slicing()
            
            print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            raise
    
    def generate_image(
        self,
        scene_description: str,
        style: str = "cinematic",
        output_path: str = None,
        width: int = 1024,
        height: int = 1920
    ) -> str:
        """
        ç”Ÿæˆå–®å¼µåœ–ç‰‡
        
        Args:
            scene_description: å ´æ™¯æè¿°
            style: é¢¨æ ¼é¸é … (cinematic, chinese_ink, ancient, fantasy, horror, hand_drawn)
            output_path: è¼¸å‡ºè·¯å¾‘
            height: åœ–ç‰‡é«˜åº¦ï¼ˆShorts æ ¼å¼ï¼‰
            width: åœ–ç‰‡å¯¬åº¦
            
        Returns:
            ç”Ÿæˆçš„åœ–ç‰‡è·¯å¾‘
        """
        if self.pipeline is None:
            self.load_model()
        
        # é¢¨æ ¼æç¤ºè©
        style_prompts = {
            "cinematic": "cinematic lighting, dramatic shadows, 4k, detailed, illustration",
            "chinese_ink": "Chinese ink painting style, traditional Chinese art, elegant brush strokes, monochrome",
            "ancient": "ancient Chinese scene, historical setting, traditional architecture, period costume",
            "fantasy": "fantasy art style, magical atmosphere, vibrant colors, ethereal",
            "horror": "dark atmosphere, eerie lighting, gothic style, mysterious shadows",
            "hand_drawn": "hand-drawn illustration, sketch style, artistic drawing, detailed linework"
        }
        
        style_prompt = style_prompts.get(style, style_prompts["cinematic"])
        
        # çµ„åˆå®Œæ•´æç¤ºè©
        full_prompt = f"{scene_description}, {style_prompt}"
        negative_prompt = "blurry, low quality, distorted, watermark, text, ugly, bad anatomy"
        
        try:
            print(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆåœ–ç‰‡: {scene_description[:30]}...")
            
            # ç”Ÿæˆåœ–ç‰‡
            image = self.pipeline(
                prompt=full_prompt,
                negative_prompt=negative_prompt,
                width=width,
                height=height,
                num_inference_steps=30,
                guidance_scale=7.5,
            ).images[0]
            
            # ä¿å­˜åœ–ç‰‡
            if output_path is None:
                import time
                timestamp = int(time.time())
                output_path = os.path.join(self.output_dir, f"image_{timestamp}.png")
            
            image.save(output_path)
            print(f"âœ… åœ–ç‰‡å·²ä¿å­˜: {output_path}")
            
            return output_path
            
        except Exception as e:
            print(f"âŒ åœ–ç‰‡ç”Ÿæˆå¤±æ•—: {e}")
            raise
    
    def generate_images_for_script(self, script_data: Dict, style: str = "cinematic") -> List[str]:
        """
        ç‚ºæ•´å€‹åŠ‡æœ¬ç”Ÿæˆæ‰€æœ‰åœ–ç‰‡
        
        Args:
            script_data: åŠ‡æœ¬æ•¸æ“šï¼ˆåŒ…å« paragraphsï¼‰
            style: åœ–ç‰‡é¢¨æ ¼
            
        Returns:
            åœ–ç‰‡è·¯å¾‘åˆ—è¡¨
        """
        paragraphs = script_data.get("paragraphs", [])
        image_paths = []
        
        print(f"ğŸ–¼ï¸  é–‹å§‹ç‚º {len(paragraphs)} å€‹æ®µè½ç”Ÿæˆåœ–ç‰‡...")
        
        for i, paragraph in enumerate(paragraphs):
            scene = paragraph.get("scene", paragraph.get("text", ""))
            output_path = os.path.join(self.output_dir, f"scene_{i+1:02d}.png")
            
            try:
                img_path = self.generate_image(
                    scene_description=scene,
                    style=style,
                    output_path=output_path
                )
                image_paths.append(img_path)
            except Exception as e:
                print(f"âš ï¸  æ®µè½ {i+1} åœ–ç‰‡ç”Ÿæˆå¤±æ•—: {e}")
                # ä½¿ç”¨é è¨­åœ–ç‰‡æˆ–è·³é
                continue
        
        print(f"âœ… å…±ç”Ÿæˆ {len(image_paths)} å¼µåœ–ç‰‡")
        return image_paths


def main():
    """æ¸¬è©¦ç”¨ä¸»å‡½æ•¸"""
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python generate_images.py <script.json> [style]")
        sys.exit(1)
    
    script_file = sys.argv[1]
    style = sys.argv[2] if len(sys.argv) > 2 else "cinematic"
    
    with open(script_file, "r", encoding="utf-8") as f:
        script_data = json.load(f)
    
    generator = ImageGenerator()
    
    try:
        image_paths = generator.generate_images_for_script(script_data, style)
        print(f"\nç”Ÿæˆçš„åœ–ç‰‡: {image_paths}")
    except Exception as e:
        print(f"éŒ¯èª¤: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()

