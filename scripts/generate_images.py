"""
åœ–ç‰‡ç”Ÿæˆæ¨¡çµ„ - ä½¿ç”¨æœ¬åœ° Stable Diffusion
ç‚ºæ¯å€‹æ®µè½ç”Ÿæˆå°æ‡‰çš„èƒŒæ™¯åœ–ç‰‡
"""

import os
import sys
from typing import List, Dict
from PIL import Image
import torch
from diffusers import StableDiffusionPipeline, StableDiffusionXLPipeline
import json

# è¨­ç½® CUDA è¨˜æ†¶é«”ç®¡ç†ç’°å¢ƒè®Šæ•¸ï¼ˆæ¸›å°‘è¨˜æ†¶é«”ç¢ç‰‡ï¼‰
os.environ.setdefault('PYTORCH_CUDA_ALLOC_CONF', 'expandable_segments:True')


class ImageGenerator:
    def __init__(
        self,
        model_type: str = "sdxl",  # "sdxl" or "sd15"
        device: str = None,
        output_dir: str = "images"
    ):
        """
        åˆå§‹åŒ–åœ–ç‰‡ç”Ÿæˆå™¨
        
        Args:
            model_type: æ¨¡å‹é¡å‹ "sdxl" æˆ– "sd15"
            device: è¨­å‚™ ("cuda", "cpu", "mps")
            output_dir: è¼¸å‡ºç›®éŒ„
        """
        self.model_type = model_type
        self.output_dir = output_dir
        self.pipeline = None
        
        # è¨­å‚™æª¢æ¸¬å’Œè¨ºæ–·
        if device:
            self.device = device
        else:
            if torch.cuda.is_available():
                self.device = "cuda"
                gpu_name = torch.cuda.get_device_name(0)
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                print(f"âœ… æª¢æ¸¬åˆ° GPU: {gpu_name} ({gpu_memory:.1f} GB VRAM)")
            else:
                self.device = "cpu"
                print("âš ï¸  è­¦å‘Š: æœªæª¢æ¸¬åˆ° CUDAï¼Œå°‡ä½¿ç”¨ CPUï¼ˆé€Ÿåº¦æ¥µæ…¢ï¼‰")
                print("   æç¤º: è«‹å®‰è£ PyTorch CUDA ç‰ˆæœ¬ä»¥ä½¿ç”¨ GPU åŠ é€Ÿ")
                print("   å®‰è£å‘½ä»¤: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
        
        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        print(f"ğŸ–¼ï¸  åœ–ç‰‡ç”Ÿæˆå™¨åˆå§‹åŒ–ï¼Œè¨­å‚™: {self.device}")
    
    def load_model(self):
        """è¼‰å…¥ Stable Diffusion æ¨¡å‹"""
        try:
            print(f"ğŸ“¦ æ­£åœ¨è¼‰å…¥ {self.model_type} æ¨¡å‹...")
            
            if self.model_type == "sdxl":
                # SDXL æ¨¡å‹ï¼ˆéœ€è¦æ›´å¤š VRAMï¼‰
                model_id = "stabilityai/stable-diffusion-xl-base-1.0"
                self.pipeline = StableDiffusionXLPipeline.from_pretrained(
                    model_id,
                    torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                    use_safetensors=True
                )
            else:
                # SD 1.5 æ¨¡å‹ï¼ˆè¼ƒè¼•é‡ï¼‰
                # ä½¿ç”¨åŸå§‹æ¨¡å‹ï¼ˆæ”¯æ´ safetensorsï¼Œå…¼å®¹æ‰€æœ‰ PyTorch ç‰ˆæœ¬ï¼‰
                # å·²å„ªåŒ–æç¤ºè©ä»¥æ›´å¥½åœ°è™•ç†ä¸­æ–‡å…§å®¹
                model_id = "runwayml/stable-diffusion-v1-5"
                print(f"ğŸ“¦ ä½¿ç”¨æ¨¡å‹: {model_id}")
                print(f"ğŸ’¡ æç¤ºï¼šå·²å„ªåŒ–ä¸­æ–‡æç¤ºè©ä»¥ç²å¾—æ›´å¥½çš„ä¸­åœ‹å‚³çµ±å ´æ™¯æ•ˆæœ")
                self.pipeline = StableDiffusionPipeline.from_pretrained(
                    model_id,
                    torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                    use_safetensors=True
                )
            
            # å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨ï¼ˆé‡å° RTX 3070 ç­‰ 8GB VRAM GPUï¼‰
            if self.device == "cuda":
                # ä½¿ç”¨ sequential CPU offloadï¼ˆæœ€ç¯€çœ VRAM çš„æ–¹æ³•ï¼‰
                try:
                    # ä½¿ç”¨ enable_sequential_cpu_offload è€Œä¸æ˜¯ enable_model_cpu_offload
                    # é€™æœƒå°‡æ¨¡å‹çš„ä¸åŒéƒ¨åˆ†æŒ‰é †åºç§»åˆ° CPUï¼Œåªåœ¨éœ€è¦æ™‚ç§»åˆ° GPU
                    self.pipeline.enable_sequential_cpu_offload()
                    # åŒæ™‚å•Ÿç”¨ attention slicing ä»¥é€²ä¸€æ­¥ç¯€çœè¨˜æ†¶é«”
                    self.pipeline.enable_attention_slicing(1)  # åˆ‡ç‰‡å¤§å° 1ï¼ˆæœ€ç¯€çœè¨˜æ†¶é«”ï¼‰
                    print("ğŸ’¾ å·²å•Ÿç”¨ sequential CPU offload + attention slicingï¼ˆç¯€çœ VRAMï¼‰")
                except Exception as e:
                    print(f"âš ï¸  Sequential CPU offload å¤±æ•—ï¼Œä½¿ç”¨æ¨™æº–æ¨¡å¼: {e}")
                    # å›é€€åˆ°æ¨™æº–å„ªåŒ–
                    self.pipeline = self.pipeline.to(self.device)
                    self.pipeline.enable_attention_slicing(1)  # ä½¿ç”¨åˆ‡ç‰‡å¤§å° 1ï¼ˆæœ€ç¯€çœè¨˜æ†¶é«”ï¼‰
                    # ä½¿ç”¨ VAE tiling è€Œä¸æ˜¯ slicingï¼ˆæ›´ç¯€çœè¨˜æ†¶é«”ï¼‰
                    if hasattr(self.pipeline, 'vae'):
                        if hasattr(self.pipeline.vae, 'enable_tiling'):
                            self.pipeline.vae.enable_tiling()
                            print("ğŸ’¾ å·²å•Ÿç”¨ VAE tiling")
            else:
                self.pipeline = self.pipeline.to(self.device)
            
            print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            raise
    
    def generate_image(
        self,
        scene_description: str,
        style: str = "cinematic",
        output_path: str = None,
        width: int = None,
        height: int = None,
        story_title: str = None,
        story_text: str = None
    ) -> str:
        """
        ç”Ÿæˆå–®å¼µåœ–ç‰‡
        
        Args:
            scene_description: å ´æ™¯æè¿°
            style: é¢¨æ ¼é¸é … (cinematic, chinese_ink, ancient, fantasy, horror, hand_drawn)
            output_path: è¼¸å‡ºè·¯å¾‘
            height: åœ–ç‰‡é«˜åº¦ï¼ˆShorts æ ¼å¼ï¼‰
            width: åœ–ç‰‡å¯¬åº¦
            
        Returns:
            ç”Ÿæˆçš„åœ–ç‰‡è·¯å¾‘
        """
        if self.pipeline is None:
            self.load_model()
        
        # æ ¹æ“š GPU VRAM è‡ªå‹•èª¿æ•´è§£æåº¦ï¼ˆ8GB VRAM ä½¿ç”¨è¼ƒå°è§£æåº¦ï¼‰
        if width is None or height is None:
            if self.device == "cuda" and torch.cuda.is_available():
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                if gpu_memory < 10:  # 8GB VRAM
                    # ä½¿ç”¨è¼ƒå°çš„è§£æåº¦ä»¥ç¯€çœ VRAM
                    width = 768
                    height = 1344  # ä¿æŒ 9:16 æ¯”ä¾‹ï¼ˆShorts æ ¼å¼ï¼‰
                    print(f"ğŸ’¾ æª¢æ¸¬åˆ° {gpu_memory:.1f}GB VRAMï¼Œä½¿ç”¨è¼ƒå°è§£æåº¦: {width}x{height}")
                else:
                    width = 1024
                    height = 1920
            else:
                width = 1024
                height = 1920
        
        # é¢¨æ ¼æç¤ºè©ï¼ˆå¢å¼·ç‰ˆï¼Œæ›´é©åˆä¸­æ–‡æ•…äº‹ï¼‰
        style_prompts = {
            "cinematic": "cinematic lighting, dramatic shadows, 4k, highly detailed, professional illustration, vibrant colors, sharp focus",
            "chinese_ink": "Chinese ink painting style, traditional Chinese art, elegant brush strokes, monochrome, classical Chinese aesthetics, traditional Chinese scene",
            "ancient": "ancient Chinese scene, historical setting, traditional Chinese architecture, period costume, Chinese historical drama style, authentic Chinese culture",
            "fantasy": "fantasy art style, magical atmosphere, vibrant colors, ethereal, Chinese fantasy elements, mystical",
            "horror": "dark atmosphere, eerie lighting, gothic style, mysterious shadows, Chinese horror aesthetic",
            "hand_drawn": "hand-drawn illustration, sketch style, artistic drawing, detailed linework, Chinese illustration style"
        }
        
        style_prompt = style_prompts.get(style, style_prompts["cinematic"])
        
        # å¢å¼·å ´æ™¯æè¿°ï¼Œçµåˆæ•…äº‹ä¸Šä¸‹æ–‡
        enhanced_scene = scene_description
        
        # å¦‚æœæœ‰æ•…äº‹æ¨™é¡Œå’Œæ–‡æœ¬ï¼Œæ·»åŠ åˆ°æç¤ºè©ä¸­ä»¥æä¾›æ›´å¤šä¸Šä¸‹æ–‡
        context_parts = []
        if story_title:
            context_parts.append(f"Story: {story_title}")
        if story_text:
            # æå–é—œéµä¿¡æ¯ï¼ˆå‰50å­—ï¼‰
            key_info = story_text[:50] if len(story_text) > 50 else story_text
            context_parts.append(f"Context: {key_info}")
        
        # æ§‹å»ºå¢å¼·å ´æ™¯æè¿°
        if any('\u4e00' <= char <= '\u9fff' for char in scene_description):
            # åŒ…å«ä¸­æ–‡å­—ç¬¦ï¼Œç¢ºä¿æ˜¯ä¸­åœ‹å‚³çµ±å ´æ™¯
            scene_with_context = scene_description
            if context_parts:
                scene_with_context = f"{scene_description}. Story context: {' '.join(context_parts)}"
            enhanced_scene = f"{scene_with_context}, ancient Chinese setting, traditional Chinese culture, historical Chinese scene, authentic Chinese period drama style"
        else:
            # è‹±æ–‡å ´æ™¯æè¿°ï¼Œä¹Ÿæ·»åŠ ä¸­åœ‹æ–‡åŒ–ä¸Šä¸‹æ–‡
            if context_parts:
                enhanced_scene = f"{scene_description}. {' '.join(context_parts)}. Ancient Chinese setting, traditional Chinese culture"
            else:
                enhanced_scene = f"{scene_description}, ancient Chinese setting, traditional Chinese culture"
        
        # çµ„åˆå®Œæ•´æç¤ºè©ï¼ˆæ›´è©³ç´°çš„æç¤ºï¼Œå¼·èª¿è¦–è¦ºç´°ç¯€ï¼‰
        full_prompt = f"{enhanced_scene}, {style_prompt}, highly detailed, vivid colors, clear composition, accurate historical details, high quality, professional illustration, masterpiece, 4k"
        negative_prompt = "blurry, low quality, distorted, watermark, text, ugly, bad anatomy, deformed, disfigured, poorly drawn, bad proportions, extra limbs, duplicate, cropped, out of frame, worst quality, low quality, jpeg artifacts, signature, username, error, Western style, modern setting, unrelated to Chinese culture"
        
        try:
            print(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆåœ–ç‰‡: {scene_description[:30]}...")
            
            # æ¸…é™¤ CUDA å¿«å–ï¼ˆé‡‹æ”¾è¨˜æ†¶é«”ï¼‰
            if self.device == "cuda":
                torch.cuda.empty_cache()
            
            # å„ªåŒ–ç”Ÿæˆåƒæ•¸ï¼ˆæ¸›å°‘æ­¥æ•¸ä»¥ç¯€çœè¨˜æ†¶é«”å’Œæ™‚é–“ï¼‰
            num_steps = 20 if self.device == "cuda" else 15  # æ¸›å°‘æ­¥æ•¸ä»¥ç¯€çœ VRAM
            
            # è¨­ç½®ç”Ÿæˆå™¨
            generator = None
            if self.device == "cuda":
                generator = torch.Generator(device="cuda")
                generator.manual_seed(42)
            
            # ç”Ÿæˆåœ–ç‰‡
            image = self.pipeline(
                prompt=full_prompt,
                negative_prompt=negative_prompt,
                width=width,
                height=height,
                num_inference_steps=num_steps,
                guidance_scale=7.5,
                generator=generator,
            ).images[0]
            
            # ç”Ÿæˆå¾Œæ¸…é™¤å¿«å–
            if self.device == "cuda":
                torch.cuda.empty_cache()
            
            # ä¿å­˜åœ–ç‰‡
            if output_path is None:
                import time
                timestamp = int(time.time())
                output_path = os.path.join(self.output_dir, f"image_{timestamp}.png")
            
            image.save(output_path)
            print(f"âœ… åœ–ç‰‡å·²ä¿å­˜: {output_path}")
            
            return output_path
            
        except Exception as e:
            print(f"âŒ åœ–ç‰‡ç”Ÿæˆå¤±æ•—: {e}")
            raise
    
    def generate_images_for_script(self, script_data: Dict, style: str = "cinematic") -> List[str]:
        """
        ç‚ºæ•´å€‹åŠ‡æœ¬ç”Ÿæˆæ‰€æœ‰åœ–ç‰‡
        
        Args:
            script_data: åŠ‡æœ¬æ•¸æ“šï¼ˆåŒ…å« paragraphs å’Œ titleï¼‰
            style: åœ–ç‰‡é¢¨æ ¼
            
        Returns:
            åœ–ç‰‡è·¯å¾‘åˆ—è¡¨
        """
        paragraphs = script_data.get("paragraphs", [])
        story_title = script_data.get("title", "")
        image_paths = []
        
        print(f"ğŸ–¼ï¸  é–‹å§‹ç‚º {len(paragraphs)} å€‹æ®µè½ç”Ÿæˆåœ–ç‰‡...")
        print(f"ğŸ“– æ•…äº‹æ¨™é¡Œ: {story_title}")
        
        for i, paragraph in enumerate(paragraphs):
            scene = paragraph.get("scene", paragraph.get("text", ""))
            text = paragraph.get("text", "")
            output_path = os.path.join(self.output_dir, f"scene_{i+1:02d}.png")
            
            try:
                # åœ¨æ¯æ¬¡ç”Ÿæˆå‰æ¸…é™¤å¿«å–
                if self.device == "cuda" and torch.cuda.is_available():
                    torch.cuda.empty_cache()
                
                # å‚³éæ•…äº‹æ¨™é¡Œå’Œæ–‡æœ¬ä»¥æä¾›ä¸Šä¸‹æ–‡
                img_path = self.generate_image(
                    scene_description=scene,
                    style=style,
                    output_path=output_path,
                    story_title=story_title,
                    story_text=text
                )
                image_paths.append(img_path)
                
                # ç”Ÿæˆå¾Œæ¸…é™¤å¿«å–
                if self.device == "cuda" and torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    
            except torch.cuda.OutOfMemoryError as e:
                print(f"âš ï¸  æ®µè½ {i+1} åœ–ç‰‡ç”Ÿæˆå¤±æ•—: VRAM ä¸è¶³")
                print(f"   å˜—è©¦æ¸…ç†è¨˜æ†¶é«”ä¸¦é‡è©¦...")
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    torch.cuda.ipc_collect()
                # è·³éé€™å¼µåœ–ç‰‡
                continue
            except Exception as e:
                print(f"âš ï¸  æ®µè½ {i+1} åœ–ç‰‡ç”Ÿæˆå¤±æ•—: {e}")
                # æ¸…é™¤å¿«å–å¾Œç¹¼çºŒ
                if self.device == "cuda" and torch.cuda.is_available():
                    torch.cuda.empty_cache()
                continue
        
        print(f"âœ… å…±ç”Ÿæˆ {len(image_paths)} å¼µåœ–ç‰‡")
        return image_paths


def main():
    """æ¸¬è©¦ç”¨ä¸»å‡½æ•¸"""
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python generate_images.py <script.json> [style]")
        sys.exit(1)
    
    script_file = sys.argv[1]
    style = sys.argv[2] if len(sys.argv) > 2 else "cinematic"
    
    with open(script_file, "r", encoding="utf-8") as f:
        script_data = json.load(f)
    
    generator = ImageGenerator()
    
    try:
        image_paths = generator.generate_images_for_script(script_data, style)
        print(f"\nç”Ÿæˆçš„åœ–ç‰‡: {image_paths}")
    except Exception as e:
        print(f"éŒ¯èª¤: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()





