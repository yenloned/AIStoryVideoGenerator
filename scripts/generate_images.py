"""
åœ–ç‰‡ç”Ÿæˆæ¨¡çµ„ - ä½¿ç”¨æœ¬åœ° Stable Diffusion
ç‚ºæ¯å€‹æ®µè½ç”Ÿæˆå°æ‡‰çš„èƒŒæ™¯åœ–ç‰‡
"""

import os
import sys
from typing import List, Dict
from PIL import Image
import torch
from diffusers import StableDiffusionPipeline, StableDiffusionXLPipeline
import json
from deep_translator import GoogleTranslator

# è¨­ç½® CUDA è¨˜æ†¶é«”ç®¡ç†ç’°å¢ƒè®Šæ•¸ï¼ˆæ¸›å°‘è¨˜æ†¶é«”ç¢ç‰‡ï¼‰
os.environ.setdefault('PYTORCH_CUDA_ALLOC_CONF', 'expandable_segments:True')


class ImageGenerator:
    def __init__(
        self,
        model_type: str = "sdxl",  # "sdxl" or "sd15"
        device: str = None,
        output_dir: str = "images"
    ):
        """
        åˆå§‹åŒ–åœ–ç‰‡ç”Ÿæˆå™¨
        
        Args:
            model_type: æ¨¡å‹é¡å‹ "sdxl" æˆ– "sd15"
            device: è¨­å‚™ ("cuda", "cpu", "mps")
            output_dir: è¼¸å‡ºç›®éŒ„
        """
        self.model_type = model_type
        self.output_dir = output_dir
        self.pipeline = None
        self.translator = GoogleTranslator(source='auto', target='en')
        self.base_character_prompt = ""  # ç”¨æ–¼ä¿æŒè§’è‰²ä¸€è‡´æ€§
        self.is_turbo = False  # æ¨™è¨˜æ˜¯å¦ç‚º Turbo æ¨¡å‹
        
        # è¨­å‚™æª¢æ¸¬å’Œè¨ºæ–·
        if device:
            self.device = device
        else:
            if torch.cuda.is_available():
                self.device = "cuda"
                gpu_name = torch.cuda.get_device_name(0)
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                print(f"âœ… æª¢æ¸¬åˆ° GPU: {gpu_name} ({gpu_memory:.1f} GB VRAM)")
            else:
                self.device = "cpu"
                print("âš ï¸  è­¦å‘Š: æœªæª¢æ¸¬åˆ° CUDAï¼Œå°‡ä½¿ç”¨ CPUï¼ˆé€Ÿåº¦æ¥µæ…¢ï¼‰")
                print("   æç¤º: è«‹å®‰è£ PyTorch CUDA ç‰ˆæœ¬ä»¥ä½¿ç”¨ GPU åŠ é€Ÿ")
                print("   å®‰è£å‘½ä»¤: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
        
        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        print(f"ğŸ–¼ï¸  åœ–ç‰‡ç”Ÿæˆå™¨åˆå§‹åŒ–ï¼Œè¨­å‚™: {self.device}")
    
    def load_model(self):
        """è¼‰å…¥ Stable Diffusion æ¨¡å‹"""
        try:
            print(f"ğŸ“¦ æ­£åœ¨è¼‰å…¥ {self.model_type} æ¨¡å‹...")
            
            if self.model_type == "sdxl":
                # SDXL æ¨¡å‹ï¼ˆéœ€è¦æ›´å¤š VRAMï¼‰
                model_id = "stabilityai/stable-diffusion-xl-base-1.0"
                self.pipeline = StableDiffusionXLPipeline.from_pretrained(
                    model_id,
                    torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                    use_safetensors=True
                )
            else:
                # SD 1.5 æ¨¡å‹ï¼ˆè¼ƒè¼•é‡ï¼‰
                # ä½¿ç”¨ Turbo æ¨¡å‹ä»¥ç²å¾—æ¥µé€Ÿç”Ÿæˆï¼ˆ1-4 æ­¥å³å¯ï¼‰
                # å„ªå…ˆé †åºï¼šSDXL Turbo (æœ€å¿«) -> SD 1.5 Turbo -> DreamShaper 8 -> Realistic Vision
                models_to_try = [
                    ("stabilityai/sdxl-turbo", "SDXL Turbo - æ¥µé€Ÿæ¨¡å‹ï¼Œ1-4 æ­¥ç”Ÿæˆ", "sdxl"),
                    ("stabilityai/sd-turbo", "SD 1.5 Turbo - æ¥µé€Ÿæ¨¡å‹ï¼Œ1-4 æ­¥ç”Ÿæˆ", "sd15"),
                    ("Lykon/DreamShaper-8", "DreamShaper 8 - æœ€æ–°ç‰ˆæœ¬ï¼Œå¹³è¡¡æ¨¡å‹", "sd15"),
                    ("SG161222/Realistic_Vision_V5.1_noVAE", "Realistic Vision - å¯«å¯¦é¢¨æ ¼", "sd15"),
                    ("runwayml/stable-diffusion-v1-5", "åŸå§‹ SD 1.5 - ç©©å®šç‰ˆæœ¬", "sd15")
                ]
                
                loaded = False
                is_turbo = False
                for model_info in models_to_try:
                    if len(model_info) == 3:
                        model_id, description, model_type = model_info
                    else:
                        model_id, description = model_info
                        model_type = "sd15"
                    
                    try:
                        print(f"ğŸ“¦ å˜—è©¦è¼‰å…¥æ¨¡å‹: {model_id}")
                        print(f"ğŸ’¡ {description}")
                        
                        # æª¢æŸ¥æ˜¯å¦ç‚º Turbo æ¨¡å‹
                        if "turbo" in model_id.lower():
                            is_turbo = True
                            print(f"âš¡ é€™æ˜¯ Turbo æ¨¡å‹ï¼Œå°‡ä½¿ç”¨æ¥µå°‘æ­¥æ•¸ï¼ˆ1-4 æ­¥ï¼‰")
                        
                        # æ ¹æ“šæ¨¡å‹é¡å‹é¸æ“‡ Pipeline
                        if model_type == "sdxl":
                            # å˜—è©¦ safetensors å„ªå…ˆ
                            try:
                                self.pipeline = StableDiffusionXLPipeline.from_pretrained(
                                    model_id,
                                    torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                                    use_safetensors=True
                                )
                            except:
                                print(f"   âš ï¸  Safetensors è¼‰å…¥å¤±æ•—ï¼Œå˜—è©¦æ¨™æº–æ ¼å¼...")
                                self.pipeline = StableDiffusionXLPipeline.from_pretrained(
                                    model_id,
                                    torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                                    use_safetensors=False
                                )
                        else:
                            # SD 1.5 æ¨¡å‹
                            try:
                                self.pipeline = StableDiffusionPipeline.from_pretrained(
                                    model_id,
                                    torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                                    use_safetensors=True
                                )
                            except:
                                print(f"   âš ï¸  Safetensors è¼‰å…¥å¤±æ•—ï¼Œå˜—è©¦æ¨™æº–æ ¼å¼...")
                                self.pipeline = StableDiffusionPipeline.from_pretrained(
                                    model_id,
                                    torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                                    use_safetensors=False
                                )
                        
                        # ä¿å­˜æ˜¯å¦ç‚º Turbo æ¨¡å‹
                        self.is_turbo = is_turbo
                        print(f"âœ… æˆåŠŸè¼‰å…¥: {model_id}")
                        loaded = True
                        break
                    except Exception as e:
                        print(f"   âŒ {model_id} è¼‰å…¥å¤±æ•—: {str(e)[:100]}...")
                        continue
                
                if not loaded:
                    raise Exception("æ‰€æœ‰æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²çµ¡é€£æ¥æˆ–æ¨¡å‹å¯ç”¨æ€§")
            
            # å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨ï¼ˆé‡å° RTX 3070 ç­‰ 8GB VRAM GPUï¼‰
            # é‡è¦ï¼šä¸ä½¿ç”¨ sequential CPU offloadï¼ˆå¤ªæ…¢ï¼‰ï¼Œä½¿ç”¨æ¨™æº– GPU æ¨¡å¼
            if self.device == "cuda":
                # ç›´æ¥è¼‰å…¥åˆ° GPUï¼ˆæœ€å¿«ï¼‰
                self.pipeline = self.pipeline.to(self.device)
                # è¼•é‡å„ªåŒ–ï¼ˆä¸å½±éŸ¿é€Ÿåº¦å¤ªå¤šï¼‰
                self.pipeline.enable_attention_slicing(4)  # åˆ‡ç‰‡å¤§å° 4ï¼ˆè¼ƒå¿«ï¼‰
                # ä½¿ç”¨ VAE tilingï¼ˆç¯€çœ VRAMï¼Œä¸å½±éŸ¿é€Ÿåº¦ï¼‰
                if hasattr(self.pipeline, 'vae'):
                    if hasattr(self.pipeline.vae, 'enable_tiling'):
                        self.pipeline.vae.enable_tiling()
                print("ğŸ’¾ å·²å•Ÿç”¨è¼•é‡å„ªåŒ–ï¼ˆGPU æ¨¡å¼ï¼Œé€Ÿåº¦å„ªå…ˆï¼‰")
            else:
                self.pipeline = self.pipeline.to(self.device)
            
            print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            raise
    
    def translate_to_english(self, text: str) -> str:
        """å°‡ä¸­æ–‡ç¿»è­¯ç‚ºè‹±æ–‡ï¼ˆSD å°è‹±æ–‡ç†è§£æ›´å¥½ï¼‰"""
        try:
            # æª¢æ¸¬æ˜¯å¦åŒ…å«ä¸­æ–‡
            if any('\u4e00' <= char <= '\u9fff' for char in text):
                translated = self.translator.translate(text)
                print(f"ğŸ”¤ ç¿»è­¯: {text[:20]}... -> {translated[:50]}...")
                return translated
            return text
        except Exception as e:
            print(f"âš ï¸  ç¿»è­¯å¤±æ•—: {e}")
            return text

    def _get_emotion_prompt_from_llm(self, emotion: str) -> str:
        """
        æ ¹æ“š LLM åˆ†æçš„æƒ…æ„Ÿè¿”å›ç›¸æ‡‰çš„æç¤ºè©
        
        Args:
            emotion: LLM åˆ†æçš„æƒ…æ„Ÿï¼ˆpositive/negative/neutralï¼‰
            
        Returns:
            æƒ…æ„Ÿç›¸é—œçš„æç¤ºè©ç‰‡æ®µ
        """
        emotion_lower = emotion.lower() if emotion else ""
        
        if "positive" in emotion_lower or "happy" in emotion_lower or "joy" in emotion_lower:
            return "joyful atmosphere, warm mood, uplifting emotions, bright lighting, positive energy"
        elif "negative" in emotion_lower or "sad" in emotion_lower or "sorrow" in emotion_lower:
            return "melancholic atmosphere, somber mood, emotional depth, dramatic lighting, expressive emotions"
        elif "neutral" in emotion_lower or "calm" in emotion_lower:
            return "calm atmosphere, peaceful mood, serene emotions, soft lighting, contemplative"
        else:
            # é»˜èªè¿”å›ç©ºï¼Œè®“ä¸‹é¢çš„å‡½æ•¸è™•ç†
            return ""
    
    def _analyze_emotional_context(self, scene_description: str, story_text: str = None) -> str:
        """
        åˆ†æå ´æ™¯çš„æƒ…æ„Ÿè‰²å½©ï¼Œæ·»åŠ ç›¸æ‡‰çš„æƒ…æ„Ÿè©å½™åˆ°æç¤ºè©
        
        Args:
            scene_description: å ´æ™¯æè¿°
            story_text: æ•…äº‹æ–‡æœ¬
            
        Returns:
            æƒ…æ„Ÿç›¸é—œçš„æç¤ºè©ç‰‡æ®µ
        """
        # åˆä½µæ–‡æœ¬é€²è¡Œåˆ†æ
        combined_text = (scene_description + " " + (story_text or "")).lower()
        
        # è² é¢æƒ…æ„Ÿé—œéµè©
        negative_keywords = [
            "æ‚²å‚·", "é›£é", "ç—›è‹¦", "çµ•æœ›", "å¤±æœ›", "æ²®å–ª", "æ†‚æ„", "å“€å‚·",
            "å®³æ€•", "ææ‡¼", "é©šæ", "æ“”æ†‚", "ç„¦æ…®", "ä¸å®‰",
            "ç”Ÿæ°£", "æ†¤æ€’", "æƒ±æ€’", "ä¸æ»¿", "æ€¨æ¨",
            "å¤±æ•—", "å¤±å»", "æ­»äº¡", "ç½é›£", "ä¸å¹¸", "å›°é›£", "å±éšª",
            "sad", "sorrow", "pain", "despair", "disappointment", "depression",
            "fear", "afraid", "worried", "anxious", "scared",
            "angry", "rage", "furious", "upset", "hate",
            "failure", "loss", "death", "disaster", "misfortune", "difficulty", "danger"
        ]
        
        # æ­£é¢æƒ…æ„Ÿé—œéµè©
        positive_keywords = [
            "å¿«æ¨‚", "é–‹å¿ƒ", "é«˜èˆˆ", "å–œæ‚…", "èˆˆå¥®", "æ­¡æ¨‚", "æ„‰å¿«", "æ»¿è¶³",
            "æˆåŠŸ", "å‹åˆ©", "ç²å¾—", "æˆå°±", "å¸Œæœ›", "ç¾å¥½", "å¹¸ç¦", "å’Œå¹³",
            "æ…¶ç¥", "æ­¡å‘¼", "è®šç¾", "æ„Ÿè¬", "æ„›", "å‹èª¼",
            "happy", "joy", "pleasure", "excited", "delighted", "cheerful", "content",
            "success", "victory", "achieve", "accomplishment", "hope", "beautiful", "peace",
            "celebrate", "cheer", "praise", "thank", "love", "friendship"
        ]
        
        # ä¸­æ€§/å¹³éœæƒ…æ„Ÿé—œéµè©
        neutral_keywords = [
            "å¹³éœ", "å®‰å¯§", "æ²‰æ€", "æ€è€ƒ", "å°ˆæ³¨", "èªçœŸ",
            "calm", "peaceful", "serene", "contemplative", "thoughtful", "focused"
        ]
        
        # æª¢æ¸¬æƒ…æ„Ÿ
        negative_count = sum(1 for keyword in negative_keywords if keyword in combined_text)
        positive_count = sum(1 for keyword in positive_keywords if keyword in combined_text)
        neutral_count = sum(1 for keyword in neutral_keywords if keyword in combined_text)
        
        # æ ¹æ“šæƒ…æ„Ÿæ·»åŠ ç›¸æ‡‰çš„æç¤ºè©
        if negative_count > positive_count and negative_count > 0:
            # è² é¢æƒ…æ„Ÿå ´æ™¯
            return "melancholic atmosphere, somber mood, emotional depth, dramatic lighting, expressive emotions"
        elif positive_count > negative_count and positive_count > 0:
            # æ­£é¢æƒ…æ„Ÿå ´æ™¯
            return "joyful atmosphere, warm mood, uplifting emotions, bright lighting, positive energy"
        elif neutral_count > 0:
            # ä¸­æ€§/å¹³éœå ´æ™¯
            return "calm atmosphere, peaceful mood, serene emotions, soft lighting, contemplative"
        else:
            # é»˜èªï¼šæ ¹æ“šå ´æ™¯æè¿°æ¨æ–·
            if any(word in combined_text for word in ["æ‚²", "å‚·", "å¤±", "æ•—", "æ­»", "sad", "loss", "fail"]):
                return "emotional depth, expressive mood"
            elif any(word in combined_text for word in ["å–œ", "æ¨‚", "æˆ", "å‹", "æ­¡", "happy", "success", "win"]):
                return "joyful mood, positive atmosphere"
            else:
                return ""  # ç„¡æ˜é¡¯æƒ…æ„Ÿï¼Œä¸æ·»åŠ 
    
    def check_safety(self, prompt: str) -> bool:
        """ç°¡å–®çš„å®‰å…¨æª¢æŸ¥"""
        unsafe_words = ["nsfw", "nude", "sex", "naked", "porn", "explicit", "gore", "blood", "violence"]
        return not any(word in prompt.lower() for word in unsafe_words)

    def generate_image(
        self,
        scene_description: str,
        style: str = "cinematic",
        output_path: str = None,
        width: int = 640,  # å¹³è¡¡è§£æåº¦ï¼ˆå¤ªé«˜æœƒå°è‡´å½å½±å’Œé‡è¤‡éƒ¨åˆ†ï¼‰
        height: int = 1152,  # ä¿æŒ 9:16 æ¯”ä¾‹
        story_title: str = None,
        story_text: str = None,
        paragraph_emotion: str = None  # LLM åˆ†æçš„æƒ…æ„Ÿ
    ) -> str:
        """
        ç”Ÿæˆå–®å¼µåœ–ç‰‡
        
        Args:
            scene_description: å ´æ™¯æè¿°
            style: é¢¨æ ¼é¸é …
            output_path: è¼¸å‡ºè·¯å¾‘
            width: åœ–ç‰‡å¯¬åº¦ (é»˜èª 1080x1920 Mobile)
            height: åœ–ç‰‡é«˜åº¦
            story_title: æ•…äº‹æ¨™é¡Œ
            story_text: æ•…äº‹æ–‡æœ¬
        """
        if self.pipeline is None:
            self.load_model()
            
        # ç¿»è­¯å ´æ™¯æè¿°
        english_description = self.translate_to_english(scene_description)
        
        # åˆ†æå ´æ™¯çš„æƒ…æ„Ÿè‰²å½©
        # å„ªå…ˆä½¿ç”¨ LLM åˆ†æçš„æƒ…æ„Ÿï¼Œå¦‚æœæ²’æœ‰å‰‡å¾æ–‡æœ¬åˆ†æ
        if paragraph_emotion:
            # ä½¿ç”¨ LLM åˆ†æçš„æƒ…æ„Ÿ
            emotional_context = self._get_emotion_prompt_from_llm(paragraph_emotion)
            print(f"ğŸ’­ ä½¿ç”¨ LLM åˆ†æçš„æƒ…æ„Ÿ: {paragraph_emotion}")
        else:
            # å¾æ–‡æœ¬åˆ†ææƒ…æ„Ÿ
            emotional_context = self._analyze_emotional_context(scene_description, story_text)
            print(f"ğŸ’­ å¾æ–‡æœ¬åˆ†æçš„æƒ…æ„Ÿ: {emotional_context[:50] if emotional_context else 'ä¸­æ€§'}")
        
        # å®šç¾©é¢¨æ ¼æç¤ºè©ï¼ˆéå¯«å¯¦é¢¨æ ¼å„ªå…ˆï¼ŒåŠ å¼·ä¸­åœ‹é¢¨æ ¼ï¼‰
        style_prompts = {
            "anime": "anime style, japanese anime studio style, cel shaded, high quality anime art, vibrant colors, stylized",
            "chinese_ink": "Chinese ink painting style, traditional Chinese shuimo painting, watercolor, monochrome with subtle color accents, artistic brushwork, traditional Chinese art, elegant and refined",
            "cinematic": "cinematic lighting, movie scene, photorealistic, 8k, dramatic atmosphere, depth of field",
            "ancient": "ancient Chinese illustration style, traditional Chinese painting, classical Chinese art, traditional art, stylized, non-photorealistic, historical Chinese aesthetics",
            "fantasy": "fantasy art style, magical atmosphere, vibrant colors, ethereal, stylized illustration",
            "horror": "dark art style, eerie atmosphere, stylized illustration, non-photorealistic",
            "hand_drawn": "hand-drawn illustration, sketch style, artistic drawing, detailed linework, stylized"
        }
        chosen_style = style_prompts.get(style, style_prompts["anime"])  # é»˜èª anime
        
        # å¦‚æœæ˜¯ä¸­åœ‹é¢¨æ ¼ï¼Œæ·»åŠ æ›´å¤šä¸­åœ‹å…ƒç´ æç¤º
        if style in ["chinese_ink", "ancient"]:
            print(f"ğŸ‡¨ğŸ‡³ ä½¿ç”¨ä¸­åœ‹å‚³çµ±é¢¨æ ¼: {style}")
        
        # è§’è‰²ä¸€è‡´æ€§è™•ç†ï¼ˆç°¡åŒ–ä»¥æ¸›å°‘ token æ•¸é‡ï¼‰
        # å¦‚æœæ˜¯æ•…äº‹çš„ç¬¬ä¸€å¼µåœ–ï¼Œæå–è§’è‰²ç‰¹å¾µä½œç‚ºåŸºç¤
        if not self.base_character_prompt and story_title:
            # ç°¡å–®æå–ï¼šå‡è¨­æ•…äº‹ä¸»è§’æ˜¯"main character"
            # é€™è£¡å¯ä»¥æ”¹é€²ç‚ºå¾æ–‡æœ¬åˆ†æä¸»è§’ç‰¹å¾µ
            self.base_character_prompt = "consistent character"
            
        # æ§‹å»ºç°¡åŒ–çš„ Prompt Templateï¼ˆä¿æŒåœ¨ 77 tokens ä»¥å…§ï¼‰
        # ç§»é™¤å†—é¤˜æè¿°ï¼Œåªä¿ç•™æ ¸å¿ƒå…ƒç´ 
        # æ ¼å¼: "{scene_description}, {style}, vertical, simple background"
        
        # ç°¡åŒ–é¢¨æ ¼æç¤ºè©ä»¥ç¯€çœ tokens
        style_short = {
            "anime": "anime style",
            "chinese_ink": "Chinese ink painting",
            "cinematic": "cinematic lighting",
            "illustration": "professional illustration"
        }
        style_short_text = style_short.get(style, "cinematic lighting")
        
        # æ§‹å»ºè©³ç´°æç¤ºè©ï¼ˆåƒè€ƒ Z Image Turbo é¢¨æ ¼ï¼‰
        # æ ¼å¼ï¼šmasterpiece, best quality, [å ´æ™¯æè¿°], (character:weight), [é¢¨æ ¼], [æ§‹åœ–], [ç´°ç¯€]
        # åƒè€ƒç¤ºä¾‹ï¼šä½¿ç”¨è©³ç´°æè¿°ã€æ¬Šé‡æ¨™è¨˜ã€å¤šå±¤æ¬¡ç´°ç¯€
        
        # æ§‹å»ºæç¤ºè©ï¼ˆåƒè€ƒç¤ºä¾‹çš„è©³ç´°é¢¨æ ¼ï¼‰
        prompt_parts = [
            "masterpiece, best quality",  # è³ªé‡æ¨™ç±¤ï¼ˆåƒè€ƒç¤ºä¾‹ï¼‰
            english_description,  # ä¸»è¦å ´æ™¯æè¿°ï¼ˆè©³ç´°æè¿°ï¼‰
        ]
        
        # æ·»åŠ è§’è‰²ä¸€è‡´æ€§ï¼ˆä½¿ç”¨æ¬Šé‡æ ¼å¼ï¼Œåƒè€ƒç¤ºä¾‹çš„ (lone warrior:1.4)ï¼‰
        if self.base_character_prompt:
            prompt_parts.append(f"({self.base_character_prompt}:1.2)")
        
        # æ·»åŠ é¢¨æ ¼å’Œç´°ç¯€ï¼ˆåƒè€ƒç¤ºä¾‹çš„è©³ç´°æè¿°ï¼‰
        prompt_parts.append(f"{chosen_style}, detailed, stylized, clear composition")
        
        # æ·»åŠ æƒ…æ„Ÿè‰²å½©ï¼ˆå¦‚æœæª¢æ¸¬åˆ°ï¼‰
        if emotional_context:
            prompt_parts.append(emotional_context)
        
        # æ·»åŠ æ§‹åœ–å’Œæ ¼å¼è¦æ±‚ï¼ˆåƒè€ƒç¤ºä¾‹çš„æ§‹åœ–æè¿°ï¼‰
        # æ·»åŠ æ›´å¤šç´°ç¯€é—œéµè©ä»¥æé«˜åœ–ç‰‡è³ªé‡
        prompt_parts.append("vertical format, simple background, avoid clutter, dynamic, highly detailed, intricate details, sharp focus, fine details, high resolution")
        
        # çµ„åˆæç¤ºè©
        prompt = ", ".join(prompt_parts)
        
        # ç¢ºä¿æç¤ºè©ä¸æœƒå¤ªé•·ï¼ˆé™åˆ¶åœ¨ 70 tokens ä»¥å…§ï¼‰
        words = prompt.split()
        if len(words) > 55:  # å¤§ç´„ 55 tokensï¼ˆç•™å‡ºå®‰å…¨é‚Šéš›åˆ° 77ï¼‰
            # ä¿ç•™æœ€é‡è¦çš„éƒ¨åˆ†
            essential_parts = [
                "masterpiece, best quality",
                english_description[:80] if len(english_description) > 80 else english_description,
            ]
            if self.base_character_prompt:
                essential_parts.append(f"({self.base_character_prompt}:1.2)")
            essential_parts.append(f"{chosen_style}, vertical format")
            prompt = ", ".join(essential_parts)
        
        print(f"ğŸ“ æç¤ºè©é•·åº¦: {len(prompt.split())} è©ï¼ˆç´„ {len(prompt.split()) * 1.3:.0f} tokensï¼‰")
        
        # Negative Prompt: å¼·åŒ–ä»¥æ¸›å°‘è§£å‰–éŒ¯èª¤å’Œé‡è¤‡éƒ¨åˆ†
        negative_prompt = "nsfw, nude, explicit, sexual, modern clothing, modern architecture, unrelated objects, blurry, low quality, distorted, watermark, bad anatomy, extra limbs, extra fingers, extra arms, extra legs, duplicated body parts, malformed limbs, missing limbs, fused fingers, too many fingers, cropped, out of frame, jpeg artifacts, text, signature, deformed, disfigured, mutation, mutated, ugly, bad proportions, extra digits, fewer digits, missing digits, bad hands, bad feet"
        
        # å®‰å…¨æª¢æŸ¥
        if not self.check_safety(prompt):
            print("âš ï¸  æç¤ºè©åŒ…å«ä¸å®‰å…¨å…§å®¹ï¼Œå·²è·³é")
            return None

        try:
            print(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆåœ–ç‰‡: {english_description[:50]}...")
            
            # æ¸…é™¤ CUDA å¿«å–
            if self.device == "cuda":
                torch.cuda.empty_cache()
            
            # è¨­ç½®ç”Ÿæˆå™¨
            generator = None
            if self.device == "cuda":
                generator = torch.Generator(device="cuda")
                generator.manual_seed(42)  # å›ºå®šç¨®å­ä»¥æé«˜ä¸€è‡´æ€§
            
            # ç”Ÿæˆåœ–ç‰‡ (é«˜è³ªé‡å„ªåŒ–ï¼Œå„ªå…ˆç´°ç¯€)
            # ä½¿ç”¨æ›´å¤šæ­¥æ•¸å’Œæ›´å¥½çš„èª¿åº¦å™¨ä»¥ç²å¾—æ›´å¥½ç´°ç¯€
            if self.is_turbo:
                # Turbo æ¨¡å‹ï¼šå¯ä»¥ç”¨æ›´å¤šæ­¥æ•¸ç²å¾—æ›´å¥½è³ªé‡
                num_steps = 4  # Turbo æ¨¡å‹ç”¨ 4 æ­¥ï¼ˆæ¯” 1 æ­¥è³ªé‡æ›´å¥½ï¼‰
                guidance_scale = 1.0  # Turbo æ¨¡å‹å¯ä»¥ç”¨å°‘é‡ guidance
                print("âš¡ ä½¿ç”¨ Turbo æ¨¡å‹ï¼ˆ4 æ­¥ç”Ÿæˆï¼Œå¹³è¡¡é€Ÿåº¦èˆ‡è³ªé‡ï¼‰")
            else:
                # æ™®é€šæ¨¡å‹ï¼šä½¿ç”¨é«˜è³ªé‡èª¿åº¦å™¨ï¼Œæ›´å¤šæ­¥æ•¸
                try:
                    from diffusers import DPMSolverMultistepScheduler
                    # ä½¿ç”¨ DPM++ 2M Karrasï¼ˆé«˜è³ªé‡ï¼‰
                    self.pipeline.scheduler = DPMSolverMultistepScheduler.from_config(
                        self.pipeline.scheduler.config,
                        use_karras_sigmas=True
                    )
                    num_steps = 20  # 20 æ­¥æ˜¯è³ªé‡èˆ‡é€Ÿåº¦çš„æœ€ä½³å¹³è¡¡ï¼ˆå¤ªå¤šæ­¥æœƒç”¢ç”Ÿå½å½±ï¼‰
                    print("ğŸ¨ ä½¿ç”¨é«˜è³ªé‡èª¿åº¦å™¨ (DPM++ 2M Karras, 20 steps)")
                except:
                    try:
                        from diffusers import EulerAncestralDiscreteScheduler
                        self.pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(
                            self.pipeline.scheduler.config
                        )
                        num_steps = 20
                        print("ğŸ¨ ä½¿ç”¨é«˜è³ªé‡èª¿åº¦å™¨ (Euler Ancestral, 20 steps)")
                    except:
                        num_steps = 20
                        print("âš™ï¸  ä½¿ç”¨é»˜èªèª¿åº¦å™¨ (20 steps)")
                guidance_scale = 7.0  # 7.0 æ˜¯æ¨™æº–å€¼ï¼Œå¤ªé«˜æœƒéåº¦é£½å’Œ
            
            print(f"â³ é–‹å§‹ç”Ÿæˆï¼ˆé è¨ˆéœ€è¦ 30-50 ç§’ï¼‰...")
            import time
            start_time = time.time()
            
            image = self.pipeline(
                prompt=prompt,
                negative_prompt=negative_prompt if not self.is_turbo else None,  # Turbo æ¨¡å‹ä¸éœ€è¦ negative prompt
                width=width,
                height=height,
                num_inference_steps=num_steps,
                guidance_scale=guidance_scale,
                generator=generator,
            ).images[0]
            
            elapsed = time.time() - start_time
            print(f"âœ… ç”Ÿæˆå®Œæˆï¼Œè€—æ™‚: {elapsed:.1f} ç§’")
            
            # ç”Ÿæˆå¾Œæ¸…é™¤å¿«å–
            if self.device == "cuda":
                torch.cuda.empty_cache()
            
            # ä¿å­˜åœ–ç‰‡
            if output_path is None:
                import time
                timestamp = int(time.time())
                output_path = os.path.join(self.output_dir, f"image_{timestamp}.png")
            
            image.save(output_path)
            print(f"âœ… åœ–ç‰‡å·²ä¿å­˜: {output_path}")
            
            return output_path
            
        except Exception as e:
            print(f"âŒ åœ–ç‰‡ç”Ÿæˆå¤±æ•—: {e}")
            # å¦‚æœå¤±æ•—ï¼Œå˜—è©¦é™ä½è§£æåº¦é‡è©¦
            if "out of memory" in str(e).lower() and width > 512:
                print("âš ï¸  VRAM ä¸è¶³ï¼Œå˜—è©¦é™ä½è§£æåº¦é‡è©¦...")
                return self.generate_image(
                    scene_description, style, output_path, 
                    width=512, height=896,  # é™ä½è§£æåº¦ä½†ä¿æŒæ¯”ä¾‹
                    story_title=story_title, story_text=story_text
                )
            raise
    
    def generate_images_for_script(self, script_data: Dict, style: str = "cinematic") -> List[str]:
        """
        ç‚ºæ•´å€‹åŠ‡æœ¬ç”Ÿæˆæ‰€æœ‰åœ–ç‰‡
        
        Args:
            script_data: åŠ‡æœ¬æ•¸æ“šï¼ˆåŒ…å« paragraphs å’Œ titleï¼‰
            style: åœ–ç‰‡é¢¨æ ¼
            
        Returns:
            åœ–ç‰‡è·¯å¾‘åˆ—è¡¨
        """
        paragraphs = script_data.get("paragraphs", [])
        story_title = script_data.get("title", "")
        image_paths = []
        
        print(f"ğŸ–¼ï¸  é–‹å§‹ç‚º {len(paragraphs)} å€‹æ®µè½ç”Ÿæˆåœ–ç‰‡...")
        print(f"ğŸ“– æ•…äº‹æ¨™é¡Œ: {story_title}")
        
        # é‡ç½®è§’è‰²ç‰¹å¾µ
        self.base_character_prompt = ""
        
        # ç²å–æ•´é«”æƒ…æ„Ÿï¼ˆå¦‚æœ LLM æä¾›äº†ï¼‰
        overall_emotion = script_data.get("emotion", None)
        
        for i, paragraph in enumerate(paragraphs):
            scene = paragraph.get("scene", paragraph.get("text", ""))
            text = paragraph.get("text", "")
            # ç²å–æ®µè½ç´šåˆ¥çš„æƒ…æ„Ÿï¼ˆå¦‚æœ LLM æä¾›äº†ï¼‰
            paragraph_emotion = paragraph.get("emotion", overall_emotion)
            output_path = os.path.join(self.output_dir, f"scene_{i+1:02d}.png")
            
            try:
                # åœ¨æ¯æ¬¡ç”Ÿæˆå‰æ¸…é™¤å¿«å–
                if self.device == "cuda" and torch.cuda.is_available():
                    torch.cuda.empty_cache()
                
                # å‚³éæ•…äº‹æ¨™é¡Œã€æ–‡æœ¬å’Œæƒ…æ„Ÿä»¥æä¾›ä¸Šä¸‹æ–‡
                img_path = self.generate_image(
                    scene_description=scene,
                    style=style,
                    output_path=output_path,
                    story_title=story_title,
                    story_text=text,
                    paragraph_emotion=paragraph_emotion  # å‚³é LLM åˆ†æçš„æƒ…æ„Ÿ
                )
                image_paths.append(img_path)
                
                # ç”Ÿæˆå¾Œæ¸…é™¤å¿«å–
                if self.device == "cuda" and torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    
            except torch.cuda.OutOfMemoryError as e:
                print(f"âš ï¸  æ®µè½ {i+1} åœ–ç‰‡ç”Ÿæˆå¤±æ•—: VRAM ä¸è¶³")
                print(f"   å˜—è©¦æ¸…ç†è¨˜æ†¶é«”ä¸¦é‡è©¦...")
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    torch.cuda.ipc_collect()
                # è·³éé€™å¼µåœ–ç‰‡
                continue
            except Exception as e:
                print(f"âš ï¸  æ®µè½ {i+1} åœ–ç‰‡ç”Ÿæˆå¤±æ•—: {e}")
                # æ¸…é™¤å¿«å–å¾Œç¹¼çºŒ
                if self.device == "cuda" and torch.cuda.is_available():
                    torch.cuda.empty_cache()
                continue
        
        print(f"âœ… å…±ç”Ÿæˆ {len(image_paths)} å¼µåœ–ç‰‡")
        return image_paths


def main():
    """æ¸¬è©¦ç”¨ä¸»å‡½æ•¸"""
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python generate_images.py <script.json> [style]")
        sys.exit(1)
    
    script_file = sys.argv[1]
    style = sys.argv[2] if len(sys.argv) > 2 else "cinematic"
    
    with open(script_file, "r", encoding="utf-8") as f:
        script_data = json.load(f)
    
    generator = ImageGenerator()
    
    try:
        image_paths = generator.generate_images_for_script(script_data, style)
        print(f"\nç”Ÿæˆçš„åœ–ç‰‡: {image_paths}")
    except Exception as e:
        print(f"éŒ¯èª¤: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()





